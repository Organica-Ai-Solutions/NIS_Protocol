"""
NIS Protocol Mock LLM Provider

This module implements a mock LLM provider for development and testing
when no real LLM provider is configured.
"""

import time
import random
from typing import Dict, Any, List, Optional, Union
import logging

from ..base_llm_provider import BaseLLMProvider, LLMResponse, LLMMessage, LLMRole

class MockProvider(BaseLLMProvider):
    """Mock LLM provider for development and testing."""
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize the Mock provider.
        
        Args:
            config: Configuration (mostly ignored for mock)
        """
        super().__init__(config)
        self.logger = logging.getLogger("mock_provider")
        
        # Mock responses for different agent types
        self.agent_responses = {
            "perception": [
                "I detect patterns in the input data suggesting archaeological significance.",
                "The visual elements show characteristics of ancient artifacts.",
                "Pattern analysis indicates potential historical relevance.",
                "I observe structural features consistent with archaeological findings."
            ],
            "memory": [
                "Information stored in semantic memory networks.",
                "Cross-referencing with existing knowledge base.",
                "Memory consolidation process initiated.",
                "Retrieving relevant historical context from long-term memory."
            ],
            "emotional": [
                "The context suggests moderate interest and curiosity.",
                "Emotional state indicates positive engagement with archaeological content.",
                "Detecting themes of historical preservation and cultural significance.",
                "Sentiment analysis shows reverence for cultural heritage."
            ],
            "executive": [
                "Analyzing options and prioritizing archaeological preservation goals.",
                "Decision framework suggests focusing on documentation and analysis.",
                "Strategic planning indicates optimal research methodology.",
                "Executive control recommends careful, systematic approach."
            ],
            "motor": [
                "Initiating documentation and cataloging procedures.",
                "Executing preservation protocols for archaeological findings.",
                "Implementing systematic recording and analysis workflow.",
                "Translating insights into actionable conservation steps."
            ],
            "default": [
                "This is a mock response from the NIS Protocol LLM system.",
                "I'm a simulated AI agent response for development purposes.",
                "Mock AI processing complete - real provider needed for production.",
                "Placeholder response generated by mock LLM provider."
            ]
        }
    
    def _get_agent_type_from_prompt(self, messages: List[LLMMessage]) -> str:
        """Determine agent type from system prompt."""
        for msg in messages:
            if msg.role == LLMRole.SYSTEM:
                prompt = msg.content.lower()
                if "perception" in prompt:
                    return "perception"
                elif "memory" in prompt:
                    return "memory"
                elif "emotional" in prompt:
                    return "emotional"
                elif "executive" in prompt:
                    return "executive"
                elif "motor" in prompt:
                    return "motor"
        return "default"
    
    async def generate(
        self,
        messages: List[LLMMessage],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        stop: Optional[List[str]] = None,
        **kwargs
    ) -> LLMResponse:
        """Generate a mock response.
        
        Args:
            messages: List of conversation messages
            temperature: Ignored for mock
            max_tokens: Ignored for mock
            stop: Ignored for mock
            **kwargs: Ignored for mock
            
        Returns:
            LLMResponse with mock content
        """
        # Simulate processing time
        await self._simulate_processing_delay()
        
        # Determine agent type and get appropriate response
        agent_type = self._get_agent_type_from_prompt(messages)
        responses = self.agent_responses.get(agent_type, self.agent_responses["default"])
        
        # Add some variety based on user input
        user_content = ""
        for msg in messages:
            if msg.role == LLMRole.USER:
                user_content = msg.content.lower()
                break
        
        # Select response based on content
        if "archaeological" in user_content or "artifact" in user_content:
            if agent_type in ["perception", "memory", "emotional"]:
                content = responses[0]  # Use first (most relevant) response
            else:
                content = random.choice(responses)
        else:
            content = random.choice(responses)
        
        # Add contextual information
        if agent_type != "default":
            content += f" [Mock {agent_type.title()} Agent Response]"
        
        return LLMResponse(
            content=content,
            metadata={
                "id": f"mock_{int(time.time() * 1000)}",
                "model": "mock-provider",
                "agent_type": agent_type,
                "provider": "mock"
            },
            usage={
                "prompt_tokens": sum(len(msg.content.split()) for msg in messages),
                "completion_tokens": len(content.split()),
                "total_tokens": sum(len(msg.content.split()) for msg in messages) + len(content.split())
            },
            model="mock-provider",
            finish_reason="stop"
        )
    
    async def embed(
        self,
        text: Union[str, List[str]],
        **kwargs
    ) -> Union[List[float], List[List[float]]]:
        """Generate mock embeddings.
        
        Args:
            text: Text or texts to embed
            **kwargs: Ignored for mock
            
        Returns:
            Mock embeddings (deterministic based on text hash)
        """
        texts = [text] if isinstance(text, str) else text
        embeddings = []
        
        for text_item in texts:
            # Generate deterministic mock embedding based on text hash
            embedding = self._generate_mock_embedding(text_item)
            embeddings.append(embedding)
        
        return embeddings[0] if isinstance(text, str) else embeddings
    
    def _generate_mock_embedding(self, text: str, dim: int = 768) -> List[float]:
        """Generate a deterministic mock embedding."""
        import hashlib
        
        # Use hash for deterministic "embedding"
        hash_bytes = hashlib.md5(text.encode()).digest()
        
        # Convert to float values between -1 and 1
        embedding = []
        for i in range(dim):
            byte_idx = i % len(hash_bytes)
            value = (hash_bytes[byte_idx] - 128) / 128.0
            embedding.append(value)
        
        return embedding
    
    async def _simulate_processing_delay(self):
        """Simulate realistic processing delay."""
        # Random delay between 0.1 and 0.5 seconds
        import asyncio
        delay = random.uniform(0.1, 0.5)
        await asyncio.sleep(delay)
    
    def get_token_count(self, text: str) -> int:
        """Get approximate token count for mock.
        
        Args:
            text: Text to count tokens for
            
        Returns:
            Approximate number of tokens (word count)
        """
        return len(text.split())
    
    async def close(self):
        """Clean up resources (nothing to clean for mock)."""
        pass 