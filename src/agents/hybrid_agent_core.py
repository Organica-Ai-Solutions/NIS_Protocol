"""
Hybrid Agent Core - Complete Laplaceâ†’KANâ†’PINNâ†’LLM Scientific Pipeline (V3 Enhanced)

This module implements the complete hybrid agent architecture with full
scientific validation pipeline including PINN physics constraint enforcement.

Architecture Flow:
[Raw Input] â†’ [Laplace Transform] â†’ [KAN Symbolic] â†’ [PINN Validation] â†’ [LLM Integration] â†’ [Output]

Week 3 Complete: PINN Physics Validation Layer integrated
"""

import torch
import numpy as np
import sympy as sp
import logging
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
from abc import ABC, abstractmethod
import time

from .signal_processing.laplace_processor import LaplaceSignalProcessor, LaplaceTransform, LaplaceTransformType
from .physics.pinn_physics_agent import PINNPhysicsAgent, PINNValidationResult
from .reasoning.kan_reasoning_agent import (
    KANSymbolicReasoningNetwork, SymbolicReasoningResult, 
    FrequencyPatternFeatures
)
from ..core.agent import NISAgent, NISLayer
from ..core.symbolic_bridge import SymbolicBridge, SymbolicExtractionResult

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LLMProvider(Enum):
    """Supported LLM providers for hybrid agents."""
    GPT4 = "gpt-4"
    CLAUDE4 = "claude-4"
    DEEPSEEK = "deepseek"
    GEMINI = "gemini"
    LOCAL_MODEL = "local"

class ProcessingLayer(Enum):
    """Scientific processing layers in the pipeline."""
    LAPLACE = "laplace"
    KAN = "kan"
    PINN = "pinn"
    LLM = "llm"

@dataclass
class CompleteScientificProcessingResult:
    """Enhanced result from complete Laplaceâ†’KANâ†’PINN scientific pipeline."""
    laplace_transform: Optional[LaplaceTransform] = None
    symbolic_extraction: Optional[SymbolicExtractionResult] = None
    kan_reasoning: Optional[SymbolicReasoningResult] = None
    pinn_validation: Optional[PINNValidationResult] = None
    physics_constraints: Optional[List[str]] = None
    integrity_score: float = 0.0
    processing_time: float = 0.0
    confidence_scores: Dict[str, float] = field(default_factory=dict)
    layer_outputs: Dict[str, Any] = field(default_factory=dict)
    symbolic_functions: List[str] = field(default_factory=list)
    physics_compliance: float = 0.0
    violations_detected: int = 0

@dataclass
class EnhancedLLMContext:
    """Enhanced context passed to LLM with complete scientific validation."""
    raw_input: Any
    scientific_result: CompleteScientificProcessingResult
    agent_type: str
    task_description: str
    constraints: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    symbolic_insights: List[str] = field(default_factory=list)
    physics_compliance: float = 1.0
    physics_violations: List[str] = field(default_factory=list)

class LLMInterface(ABC):
    """Abstract interface for LLM providers."""

    @abstractmethod
    async def generate_response(self, context: EnhancedLLMContext) -> Dict[str, Any]:
        """Generate response using the LLM."""
        pass

    @abstractmethod
    def get_provider_info(self) -> Dict[str, Any]:
        """Get information about the LLM provider."""
        pass

class EnhancedMockLLMProvider(LLMInterface):
    """Enhanced mock LLM provider with complete scientific integration."""

    def __init__(self, provider_type: LLMProvider = LLMProvider.LOCAL_MODEL):
        self.provider_type = provider_type
        self.call_count = 0

    async def generate_response(self, context: EnhancedLLMContext) -> Dict[str, Any]:
        """Generate a mock response with complete scientific integration."""
        self.call_count += 1

        # Extract scientific insights
        sci_result = context.scientific_result

        # Build comprehensive response based on all pipeline results
        response_parts = []

        if sci_result.laplace_transform:
            response_parts.append("ðŸ”§ Signal analysis completed using Laplace transform")
            response_parts.append(f"   Signal successfully transformed to frequency domain")

        if sci_result.symbolic_extraction:
            primary_func = sci_result.symbolic_extraction.primary_function
            response_parts.append(f"ðŸ§  Symbolic function extracted: {primary_func.expression}")
            response_parts.append(f"   Function type: {primary_func.function_type.value}")
            response_parts.append(f"   Extraction confidence: {primary_func.confidence:.3f}")

        if sci_result.kan_reasoning:
            response_parts.append(f"ðŸ”¬ KAN symbolic reasoning: {sci_result.kan_reasoning.symbolic_function}")
            response_parts.append(f"   Interpretability score: {sci_result.kan_reasoning.interpretability_score:.3f}")

        if sci_result.pinn_validation:
            physics_score = sci_result.pinn_validation.physics_compliance
            response_parts.append(f"ðŸ§ª PINN physics validation complete")
            response_parts.append(f"   Physics compliance: {physics_score:.3f}")

            if sci_result.pinn_validation.violations:
                response_parts.append(f"   Violations detected: {len(sci_result.pinn_validation.violations)}")
                for violation in sci_result.pinn_validation.violations[:2]:  # Show first 2
                    response_parts.append(f"   â€¢ {violation.description}")

            if sci_result.pinn_validation.corrected_function:
                response_parts.append(f"   Corrected function: {sci_result.pinn_validation.corrected_function}")

        # Add symbolic insights
        if context.symbolic_insights:
            response_parts.append("ðŸ“Š Key insights:")
            response_parts.extend([f"   â€¢ {insight}" for insight in context.symbolic_insights])

        # Add physics compliance assessment
        if context.physics_compliance < 0.8:
            response_parts.append("âš ï¸  Physics compliance below threshold - review recommended")
        elif context.physics_compliance > 0.9:
            response_parts.append("âœ… Excellent physics compliance - scientifically validated")

        response_text = "\n".join(response_parts) if response_parts else "Scientific analysis completed."

        return {
            "response": response_text,
            "confidence": sci_result.integrity_score,
            "provider": self.provider_type.value,
            "call_count": self.call_count,
            "scientific_validation": {
                "layers_processed": len(sci_result.layer_outputs),
                "symbolic_functions": sci_result.symbolic_functions,
                "physics_compliance": context.physics_compliance,
                "integrity_score": sci_result.integrity_score,
                "violations_detected": sci_result.violations_detected,
                "pinn_validation_complete": sci_result.pinn_validation is not None
            }
        }

    def get_provider_info(self) -> Dict[str, Any]:
        """Get provider information."""
        return {
            "provider": self.provider_type.value,
            "calls_made": self.call_count,
            "scientific_integration": True,
            "symbolic_reasoning": True,
            "physics_validation": True,
            "pipeline_layers": ["laplace", "kan", "pinn", "llm"]
        }

class CompleteScientificPipeline:
    """
    Complete scientific processing pipeline: Laplace â†’ KAN â†’ PINN â†’ LLM.

    Week 3 Complete: Orchestrates the full flow from signal processing through
    symbolic reasoning to physics validation.
    """

    def __init__(self):
        self.laplace_processor = LaplaceSignalProcessor()
        self.symbolic_bridge = SymbolicBridge()
        self.kan_network = KANSymbolicReasoningNetwork()
        self.pinn_agent = PINNPhysicsAgent()  # NEW: PINN integration

        self.logger = logging.getLogger("nis.complete_pipeline")

        # Enhanced pipeline statistics
        self.pipeline_stats = {
            "total_processed": 0,
            "successful_complete": 0,
            "average_processing_time": 0.0,
            "layer_success_rates": {
                "laplace": 0.0,
                "kan": 0.0,
                "pinn": 0.0,  # NEW: PINN tracking
                "llm": 0.0
            },
            "physics_compliance_average": 0.0,
            "violations_total": 0,
            "auto_corrections": 0
        }

    def process_through_complete_pipeline(self, input_data: Any,
                                        processing_config: Optional[Dict[str, Any]] = None) -> CompleteScientificProcessingResult:
        """
        Process input through complete Laplaceâ†’KANâ†’PINN scientific pipeline.

        Args:
            input_data: Raw input data (signal, numerical data, etc.)
            processing_config: Optional configuration for processing layers

        Returns:
            Complete scientific processing result with PINN validation
        """
        start_time = time.time()
        config = processing_config or {}

        result = CompleteScientificProcessingResult()

        try:
            # Stage 1: Laplace Transform
            self.logger.info("Stage 1: Laplace Transform Processing")
            laplace_result = self._process_laplace_layer(input_data, config.get("laplace", {}))
            result.laplace_transform = laplace_result
            result.layer_outputs["laplace"] = {"status": "success" if laplace_result else "failed"}

            if laplace_result:
                # Calculate Laplace confidence based on actual processing quality
                factors = ConfidenceFactors(
                    data_quality=min(1.0, len(laplace_result.transformed_signal) / 100.0) if hasattr(laplace_result, 'transformed_signal') else 0.8,
                    algorithm_stability=0.92,  # Laplace transforms are mathematically stable
                    validation_coverage=laplace_result.snr if hasattr(laplace_result, 'snr') else 0.75,
                    error_rate=laplace_result.noise_level if hasattr(laplace_result, 'noise_level') else 0.1
                )
                result.confidence_scores["laplace"] = calculate_confidence(factors)

                # Stage 2: KAN Symbolic Reasoning
                self.logger.info("Stage 2: KAN Symbolic Processing")
                symbolic_result, kan_result = self._process_kan_layer(laplace_result, config.get("kan", {}))
                result.symbolic_extraction = symbolic_result
                result.kan_reasoning = kan_result
                result.layer_outputs["kan"] = {
                    "status": "success" if symbolic_result else "failed",
                    "functions_extracted": len(result.symbolic_functions)
                }

                if symbolic_result:
                    result.confidence_scores["kan"] = symbolic_result.extraction_confidence
                    result.symbolic_functions.append(str(symbolic_result.primary_function.expression))

                    # Stage 3: PINN Physics Validation (NEW!)
                    self.logger.info("Stage 3: PINN Physics Validation")
                    pinn_result = self._process_pinn_layer(symbolic_result, config.get("pinn", {}))
                    result.pinn_validation = pinn_result
                    result.layer_outputs["pinn"] = {"status": "success" if pinn_result else "failed"}

                    if pinn_result:
                        result.confidence_scores["pinn"] = pinn_result.physics_compliance
                        result.physics_compliance = pinn_result.physics_compliance
                        result.violations_detected = len(pinn_result.violations)

                        # Update symbolic function if corrected
                        if pinn_result.corrected_function:
                            result.symbolic_functions.append(f"Corrected: {pinn_result.corrected_function}")

            # Calculate overall integrity score with PINN contribution
            result.integrity_score = self._calculate_complete_integrity_score(result.confidence_scores)
            result.processing_time = time.time() - start_time

            # Update statistics
            self._update_complete_pipeline_stats(result)

            self.logger.info(f"Complete pipeline processing finished in {result.processing_time:.3f}s")
            self.logger.info(f"Physics compliance: {result.physics_compliance:.3f}, Violations: {result.violations_detected}")

        except Exception as e:
            self.logger.error(f"Complete pipeline processing failed: {e}")
            result.layer_outputs["error"] = str(e)
            result.integrity_score = 0.0
            result.processing_time = time.time() - start_time

            return result

    def _process_laplace_layer(self, input_data: Any, config: Dict[str, Any]) -> Optional[LaplaceTransform]:
        """Process input through Laplace transform layer."""
        try:
            # Convert input to signal format
            if isinstance(input_data, (list, np.ndarray)):
                signal_data = np.array(input_data)
                time_vector = np.linspace(0, len(signal_data) * 0.1, len(signal_data))
            else:
                # Generate default signal for other input types
                signal_data = np.sin(2 * np.pi * np.linspace(0, 10, 100))
                time_vector = np.linspace(0, 10, 100)

            # Perform Laplace transform
            laplace_result = self.laplace_processor.apply_laplace_transform(
                signal_data,
                time_vector,
                transform_type=LaplaceTransformType.NUMERICAL
            )

            return laplace_result

        except Exception as e:
            self.logger.error(f"Laplace processing failed: {e}")
            return None

    def _process_kan_layer(self, laplace_transform: LaplaceTransform,
                          config: Dict[str, Any]) -> Tuple[Optional[SymbolicExtractionResult], Optional[SymbolicReasoningResult]]:
        """Process through KAN symbolic layer."""
        try:
            # Use symbolic bridge for frequency domain to symbolic conversion
            symbolic_result = self.symbolic_bridge.transform_to_symbolic(laplace_transform)

            # Create input data for KAN network from transform
            kan_input = torch.tensor(
                np.real(laplace_transform.transform_values[:10]).reshape(1, -1),
                dtype=torch.float32
            )

            # Extract frequency features
            frequency_features = self._extract_frequency_features(laplace_transform)

            # Run KAN symbolic reasoning
            kan_result = self.kan_network.extract_symbolic_function(kan_input, frequency_features)

            return symbolic_result, kan_result

        except Exception as e:
            self.logger.error(f"KAN processing failed: {e}")
            return None, None

    def _process_pinn_layer(self, symbolic_result: SymbolicExtractionResult,
                           config: Dict[str, Any]) -> Optional[PINNValidationResult]:
        """Process through PINN physics validation layer (NEW!)."""
        try:
            # Prepare PINN validation message
            pinn_message = {
                "operation": "validate_symbolic",
                "payload": {
                    "symbolic_function": str(symbolic_result.primary_function.expression),
                    "constraints": config.get("physics_laws", ["conservation_energy", "causality", "continuity"])
                }
            }

            # Process through PINN agent
            pinn_response = self.pinn_agent.process(pinn_message)

            if pinn_response["status"] == "success":
                payload = pinn_response["payload"]

                # Convert to PINNValidationResult
                from .physics.pinn_physics_agent import PhysicsViolation, ViolationType

                violations = []
                for v_data in payload["violations"]:
                    violation = PhysicsViolation(
                        violation_type=ViolationType(v_data["type"]),
                        severity=v_data["severity"],
                        description=v_data["description"],
                        suggested_correction=v_data["suggested_correction"]
                    )
                    violations.append(violation)

                corrected_function = None
                if payload["corrected_function"]:
                    corrected_function = sp.sympify(payload["corrected_function"])

                pinn_result = PINNValidationResult(
                    physics_compliance=payload["physics_compliance"],
                    violations=violations,
                    constraint_scores=payload["constraint_scores"],
                    validation_confidence=payload["validation_confidence"],
                    processing_time=payload["processing_time"],
                    symbolic_function_modified=payload["function_modified"],
                    corrected_function=corrected_function
                )

                return pinn_result
            else:
                self.logger.error(f"PINN validation failed: {pinn_response['payload']}")
                return None

        except Exception as e:
            self.logger.error(f"PINN processing failed: {e}")
            return None

    def _extract_frequency_features(self, laplace_transform: LaplaceTransform) -> FrequencyPatternFeatures:
        """Extract frequency features from Laplace transform."""
        s_values = laplace_transform.s_values
        transform_values = laplace_transform.transform_values

        # Extract magnitude and frequency information
        magnitude = np.abs(transform_values)
        frequencies = np.imag(s_values)

        # Find dominant frequencies
        peak_indices = np.argsort(magnitude)[-5:]  # Top 5 peaks
        dominant_frequencies = frequencies[peak_indices].tolist()
        magnitude_peaks = magnitude[peak_indices].tolist()

        # Calculate features
        spectral_centroid = np.sum(frequencies * magnitude) / np.sum(magnitude) if np.sum(magnitude) > 0 else 0.0
        bandwidth = np.max(frequencies) - np.min(frequencies) if len(frequencies) > 1 else 0.0
        energy = np.sum(magnitude**2)

        return FrequencyPatternFeatures(
            dominant_frequencies=dominant_frequencies,
            magnitude_peaks=magnitude_peaks,
            phase_characteristics={"variance": np.var(np.angle(transform_values))},
            spectral_centroid=float(spectral_centroid),
            bandwidth=float(bandwidth),
            energy=float(energy),
            pattern_complexity=float(np.std(magnitude) / (np.mean(magnitude) + 1e-10))
        )

    def _calculate_complete_integrity_score(self, confidence_scores: Dict[str, float]) -> float:
        """Calculate overall integrity score including PINN validation."""
        if not confidence_scores:
            return 0.0

        # Enhanced weights with PINN integration
        weights = {"laplace": 0.15, "kan": 0.35, "pinn": 0.4, "llm": 0.1}
        weighted_sum = 0.0
        total_weight = 0.0

        for layer, score in confidence_scores.items():
            if layer in weights:
                weighted_sum += score * weights[layer]
                total_weight += weights[layer]

        return weighted_sum / total_weight if total_weight > 0 else 0.0

    def _update_complete_pipeline_stats(self, result: CompleteScientificProcessingResult):
        """Update enhanced pipeline processing statistics."""
        self.pipeline_stats["total_processed"] += 1

        if result.integrity_score > 0.6:
            self.pipeline_stats["successful_complete"] += 1

        # Update average processing time
        total = self.pipeline_stats["total_processed"]
        self.pipeline_stats["average_processing_time"] = (
            (self.pipeline_stats["average_processing_time"] * (total - 1) + result.processing_time) / total
        )

        # Update layer success rates
        for layer in ["laplace", "kan", "pinn", "llm"]:
            if layer in result.confidence_scores:
                current_rate = self.pipeline_stats["layer_success_rates"][layer]
                success = 1.0 if result.confidence_scores[layer] > 0.5 else 0.0
                self.pipeline_stats["layer_success_rates"][layer] = (
                    (current_rate * (total - 1) + success) / total
                )

        # Update physics statistics
        if result.physics_compliance > 0:
            current_avg = self.pipeline_stats["physics_compliance_average"]
            self.pipeline_stats["physics_compliance_average"] = (
                (current_avg * (total - 1) + result.physics_compliance) / total
            )

        self.pipeline_stats["violations_total"] += result.violations_detected

        if result.pinn_validation and result.pinn_validation.corrected_function:
            self.pipeline_stats["auto_corrections"] += 1

    def get_complete_pipeline_statistics(self) -> Dict[str, Any]:
        """Get enhanced pipeline processing statistics."""
        total = self.pipeline_stats["total_processed"]
        success_rate = 0.0
        if total > 0:
            success_rate = self.pipeline_stats["successful_complete"] / total

        return {
            **self.pipeline_stats,
            "overall_success_rate": success_rate,
            "pipeline_complete": True,
            "pinn_integration": True
        }

class CompleteHybridAgent(NISAgent):
    """
    Complete Hybrid Agent with full Laplaceâ†’KANâ†’PINNâ†’LLM pipeline.

    Week 3 Complete: Combines LLM reasoning with complete scientific validation
    including physics constraint enforcement for robust, interpretable responses.
    """

    def __init__(self, agent_id: str, agent_type: str = "complete_hybrid",
        llm_provider: LLMProvider = LLMProvider.LOCAL_MODEL,
                 scientific_config: Optional[Dict[str, Any]] = None):
        super().__init__(agent_id, NISLayer.REASONING, f"Complete Hybrid {agent_type} agent")

        self.agent_type = agent_type
        self.llm_provider = llm_provider
        self.scientific_config = scientific_config or {}

        # Initialize enhanced components
        self.llm_interface = EnhancedMockLLMProvider(llm_provider)
        self.scientific_pipeline = CompleteScientificPipeline()

        # Enhanced processing configuration
        self.enable_symbolic_reasoning = True
        self.enable_physics_validation = True  # Always enabled for complete pipeline
        self.enable_auto_correction = self.scientific_config.get("auto_correction", True)
        self.physics_threshold = self.scientific_config.get("physics_threshold", 0.8)

        # Enhanced performance tracking
        self.agent_stats = {
            "requests_processed": 0,
            "successful_responses": 0,
            "average_response_time": 0.0,
            "scientific_validations": 0,
            "symbolic_extractions": 0,
            "physics_validations": 0,  # NEW
            "physics_violations_detected": 0,  # NEW
            "auto_corrections_applied": 0  # NEW
        }

        self.logger = logging.getLogger(f"nis.complete_hybrid.{agent_id}")
        self.logger.info(f"Initialized Complete Hybrid Agent: {agent_id}")

    def process(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process request through complete hybrid pipeline with PINN validation.

        Args:
            message: Input message with operation and payload

        Returns:
            Processed response with complete scientific validation
        """
        start_time = time.time()

        try:
            operation = message.get("operation", "analyze")
            payload = message.get("payload", {})

            # Extract input data
            input_data = payload.get("data", payload.get("input_data", []))

            if not input_data:
                return self._create_error_response("No input data provided")

            # Process through complete scientific pipeline
            scientific_result = self.scientific_pipeline.process_through_complete_pipeline(
                input_data,
                self.scientific_config
            )

            # Generate enhanced symbolic insights
            symbolic_insights = self._generate_enhanced_symbolic_insights(scientific_result)

            # Extract physics violations for LLM context
            physics_violations = []
            if scientific_result.pinn_validation:
                physics_violations = [v.description for v in scientific_result.pinn_validation.violations]

            # Create enhanced LLM context
            llm_context = EnhancedLLMContext(
                raw_input=input_data,
                scientific_result=scientific_result,
                agent_type=self.agent_type,
                task_description=payload.get("description", "Complete scientific analysis"),
                constraints=payload.get("constraints", []),
                metadata=payload.get("metadata", {}),
                symbolic_insights=symbolic_insights,
                physics_compliance=scientific_result.physics_compliance,
                physics_violations=physics_violations
            )

            # Generate LLM response
            import asyncio
            llm_response = asyncio.run(self.llm_interface.generate_response(llm_context))

            # Calculate final confidence with physics weighting
            final_confidence = min(
                scientific_result.integrity_score * 0.7 + scientific_result.physics_compliance * 0.3,
                llm_response.get("confidence", 0.5)
            )

            # Update enhanced statistics
            processing_time = time.time() - start_time
            self._update_enhanced_agent_stats(final_confidence, processing_time, scientific_result)

            return self._create_response("success", {
                "response": llm_response["response"],
                "confidence": final_confidence,
                "scientific_validation": {
                    "integrity_score": scientific_result.integrity_score,
                    "physics_compliance": scientific_result.physics_compliance,
                    "processing_time": scientific_result.processing_time,
                    "layers_processed": list(scientific_result.layer_outputs.keys()),
                    "symbolic_functions": scientific_result.symbolic_functions,
                    "confidence_scores": scientific_result.confidence_scores,
                    "violations_detected": scientific_result.violations_detected,
                    "pinn_validation_complete": scientific_result.pinn_validation is not None
                },
                "physics_validation": {
                    "compliance_score": scientific_result.physics_compliance,
                    "violations": physics_violations,
                    "auto_correction_applied": (
                        scientific_result.pinn_validation.corrected_function is not None
                        if scientific_result.pinn_validation else False
                    )
                } if scientific_result.pinn_validation else None,
                "symbolic_insights": symbolic_insights,
                "agent_type": self.agent_type,
                "llm_provider": self.llm_provider.value,
                "processing_time": processing_time,
                "pipeline_complete": True
            })

        except Exception as e:
            self.logger.error(f"Complete hybrid processing failed: {e}")
            return self._create_error_response(f"Complete processing failed: {str(e)}")

    def _generate_enhanced_symbolic_insights(self, scientific_result: CompleteScientificProcessingResult) -> List[str]:
        """Generate enhanced insights from complete scientific processing."""
        insights = []

        if scientific_result.symbolic_extraction:
            primary_func = scientific_result.symbolic_extraction.primary_function
            insights.append(f"Primary pattern identified: {primary_func.function_type.value}")
            insights.append(f"Mathematical expression: {primary_func.expression}")

            if primary_func.confidence > 0.8:
                insights.append("High confidence in symbolic representation")
            elif primary_func.confidence > 0.6:
                insights.append("Moderate confidence in symbolic representation")
            else:
                insights.append("Low confidence - pattern may be complex or noisy")

        if scientific_result.kan_reasoning:
            kan_result = scientific_result.kan_reasoning
            insights.append(f"KAN network extracted: {kan_result.symbolic_function}")
            insights.append(f"Function interpretability: {kan_result.interpretability_score:.2f}")

        # Enhanced PINN insights
        if scientific_result.pinn_validation:
            physics_score = scientific_result.pinn_validation.physics_compliance
            if physics_score > 0.9:
                insights.append("Excellent physics compliance - all fundamental laws satisfied")
            elif physics_score > 0.8:
                insights.append("Strong physics compliance - minor violations detected")
            elif physics_score > 0.6:
                insights.append("Moderate physics compliance - some physical constraints violated")
            else:
                insights.append("Poor physics compliance - significant violations of physical laws")

            if scientific_result.pinn_validation.violations:
                violation_types = set(v.violation_type.value for v in scientific_result.pinn_validation.violations)
                insights.append(f"Violation types detected: {', '.join(violation_types)}")

            if scientific_result.pinn_validation.corrected_function:
                insights.append("Auto-correction applied to improve physics compliance")

        if scientific_result.integrity_score > 0.85:
            insights.append("Overall analysis has high scientific integrity with physics validation")
        elif scientific_result.integrity_score > 0.7:
            insights.append("Overall analysis has good scientific integrity")
        else:
            insights.append("Overall analysis needs improvement - recommend additional validation")

        return insights

    def _update_enhanced_agent_stats(self, confidence: float, processing_time: float,
                                   scientific_result: CompleteScientificProcessingResult):
        """Update enhanced agent processing statistics."""
        self.agent_stats["requests_processed"] += 1

        if confidence > 0.6:
            self.agent_stats["successful_responses"] += 1

        if scientific_result.symbolic_extraction:
            self.agent_stats["symbolic_extractions"] += 1

        if scientific_result.pinn_validation:
            self.agent_stats["physics_validations"] += 1
            self.agent_stats["physics_violations_detected"] += len(scientific_result.pinn_validation.violations)

            if scientific_result.pinn_validation.corrected_function:
                self.agent_stats["auto_corrections_applied"] += 1

        # Update average processing time
        total = self.agent_stats["requests_processed"]
        self.agent_stats["average_response_time"] = (
            (self.agent_stats["average_response_time"] * (total - 1) + processing_time) / total
        )

    def get_enhanced_agent_statistics(self) -> Dict[str, Any]:
        """Get enhanced agent processing statistics."""
        total = self.agent_stats["requests_processed"]
        success_rate = 0.0
        physics_success_rate = 0.0

        if total > 0:
            success_rate = self.agent_stats["successful_responses"] / total

        if self.agent_stats["physics_validations"] > 0:
            physics_success_rate = (
                self.agent_stats["physics_validations"] -
                self.agent_stats["physics_violations_detected"]
            ) / self.agent_stats["physics_validations"]

        return {
            **self.agent_stats,
            "success_rate": success_rate,
            "physics_success_rate": physics_success_rate,
            "agent_type": self.agent_type,
            "llm_provider": self.llm_provider.value,
            "scientific_pipeline_stats": self.scientific_pipeline.get_complete_pipeline_statistics(),
            "pipeline_complete": True,
            "pinn_integration": True
        }

# Enhanced Specialized Agent Implementations

class CompleteMeTaCognitiveProcessor(CompleteHybridAgent):
    """MetaCognitive processor with complete scientific pipeline."""

    def __init__(self, agent_id: str = "complete_metacognitive_001"):
        super().__init__(
            agent_id,
            "complete_metacognitive",
            LLMProvider.GPT4,
            {
                "enable_pinn": True,
                "physics_threshold": 0.9,
                "physics_laws": ["conservation_energy", "causality", "continuity"],
                "auto_correction": True
            }
        )

class CompleteCuriosityEngine(CompleteHybridAgent):
    """Curiosity engine with enhanced novelty detection and physics validation."""

    def __init__(self, agent_id: str = "complete_curiosity_001"):
        super().__init__(
            agent_id,
            "complete_curiosity",
            LLMProvider.GEMINI,
            {
                "enable_pinn": True,
                "physics_threshold": 0.7,
                "physics_laws": ["causality", "continuity"],
                "auto_correction": False  # Let curiosity explore violations
            }
        )

class CompleteValidationAgent(CompleteHybridAgent):
    """Validation agent with strict physics-informed checking."""

    def __init__(self, agent_id: str = "complete_validation_001"):
        super().__init__(
            agent_id,
            "complete_validation",
            LLMProvider.CLAUDE4,
            {
                "enable_pinn": True,
                "physics_threshold": 0.95,  # Very strict
                "physics_laws": ["conservation_energy", "conservation_momentum", "causality", "continuity"],
                "auto_correction": True
            }
        )

# Backward compatibility aliases
HybridAgent = CompleteHybridAgent
EnhancedScientificPipeline = CompleteScientificPipeline
MetaCognitiveProcessor = CompleteMeTaCognitiveProcessor
CuriosityEngine = CompleteCuriosityEngine
ValidationAgent = CompleteValidationAgent
