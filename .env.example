# ============================================================================
# NIS PROTOCOL v3.2 - COMPLETE ENVIRONMENT CONFIGURATION
# ============================================================================
# Copy this file to the root as .env and fill in your actual values
# 
# Quick Start:
# 1. cp configs/complete.env.example .env
# 2. Edit .env with your API keys
# 3. ./start.sh
# ============================================================================

# ----------------------------------------------------------------------------
# ü§ñ LLM PROVIDER API KEYS (REQUIRED for AI functionality)
# ----------------------------------------------------------------------------
# Get your API keys from:
# ‚Ä¢ OpenAI: https://platform.openai.com/api-keys
# ‚Ä¢ Anthropic: https://console.anthropic.com/
# ‚Ä¢ DeepSeek: https://platform.deepseek.com/
# ‚Ä¢ Google: https://makersuite.google.com/app/apikey

OPENAI_API_KEY=your-openai-key-here
ANTHROPIC_API_KEY=your-anthropic-key-here
GOOGLE_API_KEY=your-google-key-here
DEEPSEEK_API_KEY=your-deepseek-key-here
KIMI_K2_API_KEY=your-kimi-key-here
NVIDIA_API_KEY=your-nvidia-api-key-here

# ----------------------------------------------------------------------------
# üéØ DEFAULT MODELS PER PROVIDER (Optional - can also be set via API)
# ----------------------------------------------------------------------------
# Override the default model for each provider
# OPENAI_MODEL=gpt-4o                          # Options: gpt-4o, gpt-4o-mini, gpt-4-turbo, o1-preview, o1-mini
# ANTHROPIC_MODEL=claude-sonnet-4-20250514     # Options: claude-sonnet-4-20250514, claude-3-5-sonnet-20241022, claude-3-opus-20240229
# GOOGLE_MODEL=gemini-pro                      # Options: gemini-pro, gemini-1.5-pro, gemini-1.5-flash
# DEEPSEEK_MODEL=deepseek-chat                 # Options: deepseek-chat, deepseek-coder, deepseek-reasoner
# KIMI_MODEL=kimi-k2-turbo-preview             # Options: kimi-k2-turbo-preview, kimi-k2-thinking, kimi-k2-0905-preview
# NVIDIA_MODEL=meta/llama-3.1-70b-instruct     # Options: meta/llama-3.1-70b-instruct, meta/llama-3.1-405b-instruct, nvidia/nemotron-4-340b-instruct

# Default provider when none specified
# DEFAULT_LLM_PROVIDER=anthropic

# ----------------------------------------------------------------------------
# üåê THIRD-PARTY PROTOCOL INTEGRATION (v4.0)
# ----------------------------------------------------------------------------
# These protocols enable agent-to-agent communication and tool sharing.
# Demo mode is used as fallback when external services aren't configured.
#
# References:
# ‚Ä¢ ACP: https://github.com/i-am-bee/acp (IBM/Linux Foundation)
# ‚Ä¢ A2A: https://github.com/google/A2A (Google)
# ‚Ä¢ MCP: Model Context Protocol (Anthropic)
# ‚Ä¢ S2A: https://github.com/google/s2a-proto (Google Secure Session)

# ----------------------------------------------------------------------------
# MCP (Model Context Protocol) - Anthropic
# ----------------------------------------------------------------------------
# For connecting to MCP servers for tool and resource access
# Local MCP server included: python -m src.protocols.mcp_server
MCP_SERVER_URL=http://localhost:3000
MCP_TIMEOUT=30
MCP_ENABLED=true
# Set to false to always use demo mode
MCP_DEMO_FALLBACK=true

# ----------------------------------------------------------------------------
# A2A (Agent-to-Agent Protocol) - Google
# ----------------------------------------------------------------------------
# For cross-platform agent coordination
# Docs: https://google.github.io/A2A/
A2A_BASE_URL=https://a2a.googleapis.com/v1
A2A_API_KEY=your-google-a2a-key-here
A2A_TIMEOUT=30
A2A_ENABLED=true
# Set to false to always use demo mode
A2A_DEMO_FALLBACK=true

# ----------------------------------------------------------------------------
# ACP (Agent Communication Protocol) - IBM/Linux Foundation
# ----------------------------------------------------------------------------
# For standardized agent-to-agent communication
# Compatible with BeeAI platform: https://beeai.dev
# Docs: https://agentcommunicationprotocol.dev
ACP_BASE_URL=http://localhost:8080
ACP_API_KEY=your-acp-key-here
ACP_TIMEOUT=30
ACP_ENABLED=true
# Set to false to always use demo mode
ACP_DEMO_FALLBACK=true

# ----------------------------------------------------------------------------
# S2A (Secure Session Agent) - Google
# ----------------------------------------------------------------------------
# For secure mTLS handshake offloading
# Docs: https://github.com/google/s2a-proto
S2A_ENABLED=false
S2A_ADDRESS=localhost:8443

# ----------------------------------------------------------------------------
# üóÑÔ∏è VECTOR DATABASE CONFIGURATION (NEW! v3.2)
# ----------------------------------------------------------------------------
# Auto-selects best available: pinecone > weaviate > hnsw > simple
VECTOR_STORE_BACKEND=auto

# Pinecone (Recommended for Production)
# Get key: https://www.pinecone.io/
PINECONE_API_KEY=your-pinecone-key-here
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX_NAME=nis-protocol-memory

# Weaviate (Alternative Production Option)
WEAVIATE_URL=http://localhost:8080
WEAVIATE_API_KEY=your-weaviate-key-here

# ----------------------------------------------------------------------------
# üóÉÔ∏è INFRASTRUCTURE (Docker Services)
# ----------------------------------------------------------------------------
COMPOSE_PROJECT_NAME=nis-protocol-v3

# PostgreSQL
DATABASE_URL=postgresql://nis_user:nis_password_2025@postgres:5432/nis_protocol_v3

# Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka:9092

# Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# ----------------------------------------------------------------------------
# üéôÔ∏è VOICE & AUDIO PROCESSING
# ----------------------------------------------------------------------------
# ElevenLabs TTS (Optional - for high-quality voice)
# Get key: https://elevenlabs.io/
ELEVENLABS_API_KEY=your-elevenlabs-key-here

# Whisper STT Configuration
WHISPER_MODEL=base

# Bark TTS (Local - no key needed)
BARK_VOICE=v2/en_speaker_6

# ----------------------------------------------------------------------------
# üéØ APPLICATION CONFIGURATION
# ----------------------------------------------------------------------------
NIS_ENV=production
LOG_LEVEL=INFO
API_HOST=0.0.0.0
API_PORT=8000
DASHBOARD_PORT=5000

# Application Behavior
ENABLE_VOICE=true
ENABLE_ANALYTICS=true
ENABLE_CACHING=true

# ----------------------------------------------------------------------------
# üìä MONITORING & OBSERVABILITY
# ----------------------------------------------------------------------------
GRAFANA_ADMIN_PASSWORD=nis_admin_2025

# Prometheus (Optional)
PROMETHEUS_PORT=9090

# ----------------------------------------------------------------------------
# üåç SPECIALIZED API INTEGRATIONS
# ----------------------------------------------------------------------------
# Copernicus Climate Data Store (for weather/climate data)
# Get key: https://cds.climate.copernicus.eu/
CDS_API_URL=https://cds.climate.copernicus.eu/api
CDS_API_KEY=your-cds-user-id:your-cds-api-key

# NVIDIA NIM (for NVIDIA models)
# Get key: https://build.nvidia.com/
NVIDIA_API_KEY=your-nvidia-key-here

# ----------------------------------------------------------------------------
# üî¨ AGENT CONFIGURATION
# ----------------------------------------------------------------------------
# Agent Orchestrator Settings
AGENT_MAX_CONCURRENT=10
AGENT_TIMEOUT=120

# Physics Validation
ENABLE_PHYSICS_VALIDATION=true
PHYSICS_AUTO_CORRECTION=true

# Research Agent
ENABLE_WEB_SEARCH=true
MAX_SEARCH_RESULTS=10

# Vision Agent - Drone Detection
# WALDO: Specialized YOLO model for overhead/drone imagery
# Classes: LightVehicle, Person, Building, UPole, Boat, Bike, Container, Truck, Gastank, Digger, Solarpanels, Bus
# Model: StephanST/WALDO30 from HuggingFace
ENABLE_WALDO_DRONE_DETECTION=false

# ----------------------------------------------------------------------------
# üíæ MEMORY & CACHING
# ----------------------------------------------------------------------------
# Memory Configuration
MEMORY_MAX_CONTEXT_LENGTH=4096
MEMORY_EMBEDDING_DIM=768
ENABLE_CONVERSATION_MEMORY=true

# Cache Configuration
CACHE_TTL=3600
CACHE_MAX_SIZE=1000

# ----------------------------------------------------------------------------
# üîê SECURITY
# ----------------------------------------------------------------------------
# JWT Configuration (Optional)
JWT_SECRET_KEY=your-secret-key-here
JWT_ALGORITHM=HS256
JWT_EXPIRATION=86400

# CORS Settings
CORS_ORIGINS=*
CORS_ALLOW_CREDENTIALS=true

# ----------------------------------------------------------------------------
# üöÄ PERFORMANCE TUNING
# ----------------------------------------------------------------------------
# Worker Configuration
WORKERS=4
MAX_REQUESTS=1000
MAX_REQUESTS_JITTER=50

# Request Limits
MAX_REQUEST_SIZE=10485760
REQUEST_TIMEOUT=300

# ----------------------------------------------------------------------------
# üß™ DEVELOPMENT & TESTING
# ----------------------------------------------------------------------------
# Development Settings (comment out in production)
# DEBUG=false
# MOCK_LLM=false
# MOCK_PROTOCOLS=false

# ----------------------------------------------------------------------------
# üì¶ OPTIONAL INTEGRATIONS
# ----------------------------------------------------------------------------
# Slack (for notifications)
SLACK_WEBHOOK_URL=your-slack-webhook-url

# Discord (for notifications)
DISCORD_WEBHOOK_URL=your-discord-webhook-url

# Sentry (for error tracking)
SENTRY_DSN=your-sentry-dsn

# ============================================================================
# END OF CONFIGURATION
# ============================================================================
# 
# Quick Checklist:
# ‚úÖ LLM API keys (OpenAI, Anthropic, Google) - REQUIRED
# ‚öôÔ∏è  Protocol keys (MCP, A2A, ACP) - Optional but recommended
# üóÑÔ∏è  Vector DB (Pinecone or Weaviate) - Optional but recommended for production
# üéôÔ∏è  Voice keys (ElevenLabs) - Optional
# üåç  Specialized APIs (CDS, NVIDIA) - Optional
# 
# For more info: See system/docs/PROTOCOL_CONFIGURATION.md
# ============================================================================

